{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467b192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: darts in ./.venv/lib/python3.12/site-packages (0.38.0)\n",
      "Requirement already satisfied: holidays>=0.11.1 in ./.venv/lib/python3.12/site-packages (from darts) (0.81)\n",
      "Requirement already satisfied: joblib>=0.16.0 in ./.venv/lib/python3.12/site-packages (from darts) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.12/site-packages (from darts) (3.10.6)\n",
      "Requirement already satisfied: narwhals>=1.25.1 in ./.venv/lib/python3.12/site-packages (from darts) (2.7.0)\n",
      "Requirement already satisfied: nfoursid>=1.0.0 in ./.venv/lib/python3.12/site-packages (from darts) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.3.3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in ./.venv/lib/python3.12/site-packages (from darts) (2.3.3)\n",
      "Requirement already satisfied: pyod>=0.9.5 in ./.venv/lib/python3.12/site-packages (from darts) (2.0.5)\n",
      "Requirement already satisfied: requests>=2.22.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.32.5)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in ./.venv/lib/python3.12/site-packages (from darts) (1.7.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.venv/lib/python3.12/site-packages (from darts) (1.16.2)\n",
      "Requirement already satisfied: shap>=0.40.0 in ./.venv/lib/python3.12/site-packages (from darts) (0.48.0)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in ./.venv/lib/python3.12/site-packages (from darts) (0.14.5)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in ./.venv/lib/python3.12/site-packages (from darts) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from darts) (4.15.0)\n",
      "Requirement already satisfied: xarray>=0.17.0 in ./.venv/lib/python3.12/site-packages (from darts) (2025.9.1)\n",
      "Requirement already satisfied: pytorch-lightning<2.5.3,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.5.2)\n",
      "Requirement already satisfied: tensorboardX>=2.1 in ./.venv/lib/python3.12/site-packages (from darts) (2.6.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.12/site-packages (from holidays>=0.11.1->darts) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (3.2.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.5->darts) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.5->darts) (2025.2)\n",
      "Requirement already satisfied: numba>=0.51 in ./.venv/lib/python3.12/site-packages (from pyod>=0.9.5->darts) (0.62.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./.venv/lib/python3.12/site-packages (from pytorch-lightning<2.5.3,>=2.0.0->darts) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (2025.9.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./.venv/lib/python3.12/site-packages (from pytorch-lightning<2.5.3,>=2.0.0->darts) (1.8.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in ./.venv/lib/python3.12/site-packages (from pytorch-lightning<2.5.3,>=2.0.0->darts) (0.15.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (2025.10.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.6.0->darts) (3.6.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in ./.venv/lib/python3.12/site-packages (from shap>=0.40.0->darts) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.12/site-packages (from shap>=0.40.0->darts) (3.1.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in ./.venv/lib/python3.12/site-packages (from statsmodels>=0.14.0->darts) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in ./.venv/lib/python3.12/site-packages (from tensorboardX>=2.1->darts) (6.32.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.19.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.1.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (3.12.15)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in ./.venv/lib/python3.12/site-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.45.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil->holidays>=0.11.1->darts) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->darts) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->darts) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (1.21.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catboost in ./.venv/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from catboost) (3.10.6)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./.venv/lib/python3.12/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.venv/lib/python3.12/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from catboost) (1.16.2)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.12/site-packages (from catboost) (6.3.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.12/site-packages (from plotly->catboost) (2.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install darts\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20dfa585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The StatsForecast module could not be imported. To enable support for the AutoARIMA, AutoETS and Croston models, please consider installing it.\n",
      "The `XGBoost` module could not be imported. To enable XGBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "The `XGBoost` module could not be imported. To enable XGBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from darts import TimeSeries\n",
    "from darts.models import CatBoostModel\n",
    "import pandas as pd\n",
    "import os\n",
    "import kaggle_metric\n",
    "import utils\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabfea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8571ae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date_arrival",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "rm_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "net_weight",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a6f29418-2a77-4b07-a346-b7f0abb050e2",
       "rows": [
        [
         "6045",
         "2021-01-02 00:00:00",
         "342",
         "0.0"
        ],
        [
         "6046",
         "2021-01-03 00:00:00",
         "342",
         "0.0"
        ],
        [
         "6047",
         "2021-01-04 00:00:00",
         "342",
         "0.0"
        ],
        [
         "6048",
         "2021-01-05 00:00:00",
         "342",
         "0.0"
        ],
        [
         "6049",
         "2021-01-06 00:00:00",
         "342",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_arrival</th>\n",
       "      <th>rm_id</th>\n",
       "      <th>net_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_arrival  rm_id  net_weight\n",
       "6045   2021-01-02    342         0.0\n",
       "6046   2021-01-03    342         0.0\n",
       "6047   2021-01-04    342         0.0\n",
       "6048   2021-01-05    342         0.0\n",
       "6049   2021-01-06    342         0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.create_df(\"./data/kernel/receivals.csv\")\n",
    "df = df[df[\"date_arrival\"] > \"2021-01-01\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d1da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_lst = TimeSeries.from_group_dataframe(df, \"rm_id\", \"date_arrival\", \"net_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269eb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping rm_id 342.0 because all features are constant.\n",
      "Skipping rm_id 343.0 because all features are constant.\n",
      "Skipping rm_id 345.0 because all features are constant.\n",
      "Skipping rm_id 346.0 because all features are constant.\n",
      "Skipping rm_id 347.0 because all features are constant.\n",
      "Skipping rm_id 348.0 because all features are constant.\n",
      "Skipping rm_id 353.0 because all features are constant.\n",
      "Skipping rm_id 354.0 because all features are constant.\n",
      "Skipping rm_id 355.0 because all features are constant.\n",
      "Skipping rm_id 357.0 because all features are constant.\n",
      "Skipping rm_id 358.0 because all features are constant.\n",
      "Skipping rm_id 360.0 because all features are constant.\n",
      "Skipping rm_id 362.0 because all features are constant.\n",
      "Skipping rm_id 364.0 because all features are constant.\n",
      "Skipping rm_id 365.0 because all features are constant.\n",
      "Skipping rm_id 366.0 because all features are constant.\n",
      "Skipping rm_id 367.0 because all features are constant.\n",
      "Skipping rm_id 368.0 because all features are constant.\n",
      "Skipping rm_id 369.0 because all features are constant.\n",
      "Skipping rm_id 374.0 because all features are constant.\n",
      "Skipping rm_id 375.0 because all features are constant.\n",
      "Skipping rm_id 378.0 because all features are constant.\n",
      "Skipping rm_id 379.0 because all features are constant.\n",
      "Skipping rm_id 380.0 because all features are constant.\n",
      "Skipping rm_id 381.0 because all features are constant.\n",
      "Skipping rm_id 383.0 because all features are constant.\n",
      "Skipping rm_id 386.0 because all features are constant.\n",
      "Skipping rm_id 387.0 because all features are constant.\n",
      "Skipping rm_id 388.0 because all features are constant.\n",
      "Skipping rm_id 389.0 because all features are constant.\n",
      "Skipping rm_id 390.0 because all features are constant.\n",
      "Skipping rm_id 1842.0 because all features are constant.\n",
      "Skipping rm_id 1843.0 because all features are constant.\n",
      "Skipping rm_id 1844.0 because all features are constant.\n",
      "Skipping rm_id 1845.0 because all features are constant.\n",
      "Skipping rm_id 1846.0 because all features are constant.\n",
      "Skipping rm_id 1850.0 because all features are constant.\n",
      "Skipping rm_id 1851.0 because all features are constant.\n",
      "Skipping rm_id 1852.0 because all features are constant.\n",
      "Skipping rm_id 1853.0 because all features are constant.\n",
      "Skipping rm_id 1854.0 because all features are constant.\n",
      "Skipping rm_id 1857.0 because all features are constant.\n",
      "Skipping rm_id 1858.0 because all features are constant.\n",
      "Skipping rm_id 1866.0 because all features are constant.\n",
      "Skipping rm_id 1867.0 because all features are constant.\n",
      "Skipping rm_id 1868.0 because all features are constant.\n",
      "Skipping rm_id 1871.0 because all features are constant.\n",
      "Skipping rm_id 1872.0 because all features are constant.\n",
      "Skipping rm_id 1873.0 because all features are constant.\n",
      "Skipping rm_id 1874.0 because all features are constant.\n",
      "Skipping rm_id 1875.0 because all features are constant.\n",
      "Skipping rm_id 1876.0 because all features are constant.\n",
      "Skipping rm_id 1882.0 because all features are constant.\n",
      "Skipping rm_id 1901.0 because all features are constant.\n",
      "Skipping rm_id 1902.0 because all features are constant.\n",
      "Skipping rm_id 1903.0 because all features are constant.\n",
      "Skipping rm_id 1904.0 because all features are constant.\n",
      "Skipping rm_id 1905.0 because all features are constant.\n",
      "Skipping rm_id 1906.0 because all features are constant.\n",
      "Skipping rm_id 1907.0 because all features are constant.\n",
      "Skipping rm_id 1908.0 because all features are constant.\n",
      "Skipping rm_id 1909.0 because all features are constant.\n",
      "Skipping rm_id 1981.0 because all features are constant.\n",
      "Skipping rm_id 1982.0 because all features are constant.\n",
      "Skipping rm_id 2001.0 because all features are constant.\n",
      "Skipping rm_id 2061.0 because all features are constant.\n",
      "Skipping rm_id 2102.0 because all features are constant.\n",
      "Skipping rm_id 2122.0 because all features are constant.\n",
      "Skipping rm_id 2127.0 because all features are constant.\n",
      "Skipping rm_id 2128.0 because all features are constant.\n",
      "Skipping rm_id 2138.0 because all features are constant.\n",
      "Skipping rm_id 2139.0 because all features are constant.\n",
      "Skipping rm_id 2141.0 because all features are constant.\n",
      "Skipping rm_id 2146.0 because all features are constant.\n",
      "Skipping rm_id 2148.0 because all features are constant.\n",
      "Skipping rm_id 2149.0 because all features are constant.\n",
      "Skipping rm_id 2150.0 because all features are constant.\n",
      "Skipping rm_id 2151.0 because all features are constant.\n",
      "Skipping rm_id 2152.0 because all features are constant.\n",
      "Skipping rm_id 2155.0 because all features are constant.\n",
      "Skipping rm_id 2156.0 because all features are constant.\n",
      "Skipping rm_id 2157.0 because all features are constant.\n",
      "Skipping rm_id 2158.0 because all features are constant.\n",
      "Skipping rm_id 2159.0 because all features are constant.\n",
      "Skipping rm_id 2182.0 because all features are constant.\n",
      "Skipping rm_id 2201.0 because all features are constant.\n",
      "Skipping rm_id 2222.0 because all features are constant.\n",
      "Skipping rm_id 2223.0 because all features are constant.\n",
      "Skipping rm_id 2261.0 because all features are constant.\n",
      "Skipping rm_id 2282.0 because all features are constant.\n",
      "Skipping rm_id 2283.0 because all features are constant.\n",
      "Skipping rm_id 2285.0 because all features are constant.\n",
      "Skipping rm_id 2302.0 because all features are constant.\n",
      "Skipping rm_id 2304.0 because all features are constant.\n",
      "Skipping rm_id 2322.0 because all features are constant.\n",
      "Skipping rm_id 2323.0 because all features are constant.\n",
      "Skipping rm_id 2341.0 because all features are constant.\n",
      "Skipping rm_id 2343.0 because all features are constant.\n",
      "Skipping rm_id 2344.0 because all features are constant.\n",
      "Skipping rm_id 2345.0 because all features are constant.\n",
      "Skipping rm_id 2347.0 because all features are constant.\n",
      "Skipping rm_id 2348.0 because all features are constant.\n",
      "Skipping rm_id 2362.0 because all features are constant.\n",
      "Skipping rm_id 2363.0 because all features are constant.\n",
      "Skipping rm_id 2364.0 because all features are constant.\n",
      "Skipping rm_id 2365.0 because all features are constant.\n",
      "Skipping rm_id 2401.0 because all features are constant.\n",
      "Skipping rm_id 2421.0 because all features are constant.\n",
      "Skipping rm_id 2441.0 because all features are constant.\n",
      "Skipping rm_id 2481.0 because all features are constant.\n",
      "Skipping rm_id 2742.0 because all features are constant.\n",
      "Skipping rm_id 2821.0 because all features are constant.\n",
      "Skipping rm_id 2841.0 because all features are constant.\n",
      "Skipping rm_id 2861.0 because all features are constant.\n",
      "Skipping rm_id 3022.0 because all features are constant.\n",
      "Skipping rm_id 3144.0 because all features are constant.\n",
      "Skipping rm_id 3201.0 because all features are constant.\n",
      "Skipping rm_id 3461.0 because all features are constant.\n",
      "Skipping rm_id 4222.0 because all features are constant.\n",
      "Skipping rm_id 4263.0 because all features are constant.\n",
      "Skipping rm_id 4302.0 because all features are constant.\n",
      "Skipping rm_id 4343.0 because all features are constant.\n",
      "Skipping rm_id 4381.0 because all features are constant.\n",
      "Skipping rm_id 4401.0 because all features are constant.\n",
      "Skipping rm_id 4441.0 because all features are constant.\n",
      "Skipping rm_id 4443.0 because all features are constant.\n",
      "Skipping rm_id 4461.0 because all features are constant.\n",
      "Skipping rm_id 4462.0 because all features are constant.\n",
      "Skipping rm_id 4463.0 because all features are constant.\n",
      "Skipping rm_id 4481.0 because all features are constant.\n",
      "Skipping rm_id 4501.0 because all features are constant.\n"
     ]
    }
   ],
   "source": [
    "series_dict = {}\n",
    "train_dict = {}\n",
    "val_dict = {}\n",
    "scaler_dict = {}\n",
    "\n",
    "for i in range(len(series_lst)):\n",
    "    train_i, val_i = series_lst[i].split_after(0.8)\n",
    "    rm_id = (\n",
    "        series_lst[i].static_covariates[\"rm_id\"]\n",
    "        if \"rm_id\" in series_lst[i].static_covariates\n",
    "        else None\n",
    "    )\n",
    "    rm_id = rm_id.values[0]\n",
    "\n",
    "    # Filter out series where all features are constant (required for CatBoost)\n",
    "    if (train_i.values() == train_i.values()[0]).all():\n",
    "        print(f\"Skipping rm_id {rm_id} because all features are constant.\")\n",
    "        continue\n",
    "    scaler = Scaler()\n",
    "    train_dict[rm_id] = scaler.fit_transform(train_i)  # fit transform on train\n",
    "    # no transform on val original values only used for calculating score\n",
    "    val_dict[rm_id] = scaler.transform(val_i)\n",
    "    # transform on full series for future preditction\n",
    "    series_dict[rm_id] = scaler.transform(series_lst[i])\n",
    "    scaler_dict[rm_id] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e371019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for rm_id 2121.0: 1.0738101380835035, Quantile Loss: 0.0\n",
      "MSE for rm_id 2123.0: 43140684.79865156, Quantile Loss: 757.4535581117328\n",
      "MSE for rm_id 2124.0: 151143441.17020875, Quantile Loss: 2196.246575342466\n",
      "MSE for rm_id 2125.0: 309898344.4226511, Quantile Loss: 2335.0173357542903\n",
      "MSE for rm_id 2129.0: 6578605575.619448, Quantile Loss: 14323.74201680501\n",
      "MSE for rm_id 2130.0: 54163611678646.414, Quantile Loss: 1199401.6984872213\n",
      "MSE for rm_id 2131.0: 79718816596.17654, Quantile Loss: 47778.6260051487\n",
      "MSE for rm_id 2132.0: 8871175119.750408, Quantile Loss: 16288.786833032118\n",
      "MSE for rm_id 2133.0: 2201970657.954955, Quantile Loss: 7989.424147336068\n",
      "MSE for rm_id 2134.0: 618247132689.5089, Quantile Loss: 135892.24895405947\n",
      "MSE for rm_id 2135.0: 209813675034.0009, Quantile Loss: 82875.55134830788\n",
      "MSE for rm_id 2140.0: 2226325578015.2725, Quantile Loss: 267959.6347645151\n",
      "MSE for rm_id 2142.0: 372051509979.2396, Quantile Loss: 105872.48819010126\n",
      "MSE for rm_id 2143.0: 23193333827.87648, Quantile Loss: 27001.861718513446\n",
      "MSE for rm_id 2144.0: 64203733203.63498, Quantile Loss: 44056.40820744042\n",
      "MSE for rm_id 2145.0: 51572850182.66067, Quantile Loss: 39397.164948757294\n",
      "MSE for rm_id 2147.0: 3533606397.1299205, Quantile Loss: 10489.02377359321\n",
      "MSE for rm_id 2153.0: 614.8999872692654, Quantile Loss: 0.0\n",
      "MSE for rm_id 2160.0: 176.02873834090795, Quantile Loss: 0.0\n",
      "MSE for rm_id 2161.0: 9961543.803488465, Quantile Loss: 596.9589041095891\n",
      "MSE for rm_id 2284.0: 1.83192980269377, Quantile Loss: 0.0\n",
      "MSE for rm_id 2402.0: 16.181036846654298, Quantile Loss: 0.0\n",
      "MSE for rm_id 2482.0: 510.0920088796059, Quantile Loss: 0.0\n",
      "MSE for rm_id 2521.0: 8071.83205131412, Quantile Loss: 0.0\n",
      "MSE for rm_id 2561.0: 3.7751285609913734, Quantile Loss: 0.0\n",
      "MSE for rm_id 2601.0: 2226.7879281142045, Quantile Loss: 0.0\n",
      "MSE for rm_id 2741.0: 48227795129.2705, Quantile Loss: 37246.22282691947\n",
      "MSE for rm_id 2761.0: 29712.971222562723, Quantile Loss: 137.89960689733724\n",
      "MSE for rm_id 2981.0: 3477237.039735817, Quantile Loss: 1491.7880899882946\n",
      "MSE for rm_id 3005.0: 1912.7763147011738, Quantile Loss: 0.0\n",
      "MSE for rm_id 3101.0: 9.463774925315812, Quantile Loss: 0.0\n",
      "MSE for rm_id 3121.0: 13071133841.458763, Quantile Loss: 18487.938420864197\n",
      "MSE for rm_id 3122.0: 5412208155631.072, Quantile Loss: 409270.5676875146\n",
      "MSE for rm_id 3123.0: 3382314596255.437, Quantile Loss: 316631.53966902907\n",
      "MSE for rm_id 3124.0: 6433257340916.682, Quantile Loss: 454382.39526109275\n",
      "MSE for rm_id 3125.0: 8623482153664.161, Quantile Loss: 515748.0869551034\n",
      "MSE for rm_id 3126.0: 7680421510831.532, Quantile Loss: 486179.85674544965\n",
      "MSE for rm_id 3142.0: 17555643291.45688, Quantile Loss: 23042.993839990184\n",
      "MSE for rm_id 3161.0: 58728.5208884353, Quantile Loss: 193.87174463701146\n",
      "MSE for rm_id 3162.0: 36069.68083854723, Quantile Loss: 151.93615677866225\n",
      "MSE for rm_id 3222.0: 568.255025044063, Quantile Loss: 0.0\n",
      "MSE for rm_id 3241.0: 660.8188838434309, Quantile Loss: 0.0\n",
      "MSE for rm_id 3265.0: 52246733221.93956, Quantile Loss: 43412.75833776353\n",
      "MSE for rm_id 3282.0: 5115834206678.455, Quantile Loss: 395780.9880738461\n",
      "MSE for rm_id 3362.0: 61453284847.13697, Quantile Loss: 36963.73698630137\n",
      "MSE for rm_id 3381.0: 732926014.974846, Quantile Loss: 4347.557953925316\n",
      "MSE for rm_id 3421.0: 52523765856.11114, Quantile Loss: 39454.52503868288\n",
      "MSE for rm_id 3441.0: 6811.831119065677, Quantile Loss: 0.0\n",
      "MSE for rm_id 3481.0: 499.329805745837, Quantile Loss: 0.0\n",
      "MSE for rm_id 3501.0: 471.54626971436016, Quantile Loss: 0.0\n",
      "MSE for rm_id 3541.0: 100.42253456713493, Quantile Loss: 0.0\n",
      "MSE for rm_id 3581.0: 1696.0706814031398, Quantile Loss: 0.0\n",
      "MSE for rm_id 3601.0: 25753369.374772903, Quantile Loss: 883.2253424657533\n",
      "MSE for rm_id 3621.0: 247955271.2652981, Quantile Loss: 2444.0068493150684\n",
      "MSE for rm_id 3642.0: 19250048525.773396, Quantile Loss: 24296.631192597324\n",
      "MSE for rm_id 3701.0: 2018498545.853687, Quantile Loss: 4720.602739726028\n",
      "MSE for rm_id 3761.0: 22347.90838311914, Quantile Loss: 96.48848442791895\n",
      "MSE for rm_id 3762.0: 474.2467395783438, Quantile Loss: 0.0\n",
      "MSE for rm_id 3781.0: 27242382371093.523, Quantile Loss: 949919.1788215111\n",
      "MSE for rm_id 3802.0: 478.6247677166756, Quantile Loss: 0.0\n",
      "MSE for rm_id 3821.0: 930.2442770693007, Quantile Loss: 0.0\n",
      "MSE for rm_id 3841.0: 3309.521919841466, Quantile Loss: 0.0\n",
      "MSE for rm_id 3865.0: 33386092228934.79, Quantile Loss: 1012469.7774617109\n",
      "MSE for rm_id 3883.0: 34236229178.253025, Quantile Loss: 33394.85217881204\n",
      "MSE for rm_id 3901.0: 1242486853710.2847, Quantile Loss: 192310.78418927843\n",
      "MSE for rm_id 3921.0: 504.9494862435682, Quantile Loss: 0.0\n",
      "MSE for rm_id 3941.0: 43.70010341629313, Quantile Loss: 0.0\n",
      "MSE for rm_id 4021.0: 5851919752.844201, Quantile Loss: 13791.246575342466\n",
      "MSE for rm_id 4044.0: 777.6799151515096, Quantile Loss: 0.0\n",
      "MSE for rm_id 4081.0: 3764649907.096519, Quantile Loss: 11405.17808219178\n",
      "MSE for rm_id 4101.0: 332.80390443020735, Quantile Loss: 0.0\n",
      "MSE for rm_id 4161.0: 5217783.420863267, Quantile Loss: 233.2054794520548\n",
      "Average MSE across all rm_ids: 2175835172742.9514\n",
      "Average Quantile Loss across all rm_ids: 97695.86356333006\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "loss = []\n",
    "quantile_losses = []\n",
    "\n",
    "preds_lst = []\n",
    "val_lst = []\n",
    "\n",
    "for key in train_dict:\n",
    "    train_values = train_dict[key].values()\n",
    "    model = CatBoostModel(lags=30, random_state=random_state)\n",
    "    model.fit(train_dict[key], val_series=val_dict[key])\n",
    "    preds = model.predict(len(val_dict[key]), series=train_dict[key])\n",
    "    model_dict[key] = model\n",
    "\n",
    "    # Inverse transform predictions and validation data\n",
    "    scaler = scaler_dict[key]\n",
    "    cum_preds = scaler.inverse_transform(preds)\n",
    "    cum_val = scaler.inverse_transform(val_dict[key]).cumsum()\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = metrics.mse(cum_val, cum_preds)\n",
    "    loss.append(mse)\n",
    "\n",
    "    cum_preds = cum_preds.values().clip(min=0)\n",
    "    cum_preds[cum_preds < 100] = 0  # set predictions below 100 to 0\n",
    "    cum_val = cum_val.values()\n",
    "\n",
    "    # Calculate Quantile Loss\n",
    "    ql = kaggle_metric.quantile_error(cum_val, cum_preds)\n",
    "    quantile_losses.append(ql)\n",
    "\n",
    "    # Store predictions and actual values\n",
    "    preds_lst.append(cum_preds.flatten())\n",
    "    val_lst.append(cum_val.flatten())\n",
    "\n",
    "    print(f\"MSE for rm_id {key}: {mse}, Quantile Loss: {ql}\")\n",
    "\n",
    "print(f\"Average MSE across all rm_ids: {np.mean(loss)}\")\n",
    "print(f\"Average Quantile Loss across all rm_ids: {np.mean(quantile_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "729331cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rm_id 342\n",
      "No model for rm_id 342, setting predicted_weight to 0\n",
      "Processing rm_id 343\n",
      "No model for rm_id 343, setting predicted_weight to 0\n",
      "Processing rm_id 345\n",
      "No model for rm_id 345, setting predicted_weight to 0\n",
      "Processing rm_id 346\n",
      "No model for rm_id 346, setting predicted_weight to 0\n",
      "Processing rm_id 347\n",
      "No model for rm_id 347, setting predicted_weight to 0\n",
      "Processing rm_id 348\n",
      "No model for rm_id 348, setting predicted_weight to 0\n",
      "Processing rm_id 353\n",
      "No model for rm_id 353, setting predicted_weight to 0\n",
      "Processing rm_id 354\n",
      "No model for rm_id 354, setting predicted_weight to 0\n",
      "Processing rm_id 355\n",
      "No model for rm_id 355, setting predicted_weight to 0\n",
      "Processing rm_id 357\n",
      "No model for rm_id 357, setting predicted_weight to 0\n",
      "Processing rm_id 358\n",
      "No model for rm_id 358, setting predicted_weight to 0\n",
      "Processing rm_id 360\n",
      "No model for rm_id 360, setting predicted_weight to 0\n",
      "Processing rm_id 362\n",
      "No model for rm_id 362, setting predicted_weight to 0\n",
      "Processing rm_id 364\n",
      "No model for rm_id 364, setting predicted_weight to 0\n",
      "Processing rm_id 365\n",
      "No model for rm_id 365, setting predicted_weight to 0\n",
      "Processing rm_id 366\n",
      "No model for rm_id 366, setting predicted_weight to 0\n",
      "Processing rm_id 367\n",
      "No model for rm_id 367, setting predicted_weight to 0\n",
      "Processing rm_id 368\n",
      "No model for rm_id 368, setting predicted_weight to 0\n",
      "Processing rm_id 369\n",
      "No model for rm_id 369, setting predicted_weight to 0\n",
      "Processing rm_id 374\n",
      "No model for rm_id 374, setting predicted_weight to 0\n",
      "Processing rm_id 375\n",
      "No model for rm_id 375, setting predicted_weight to 0\n",
      "Processing rm_id 378\n",
      "No model for rm_id 378, setting predicted_weight to 0\n",
      "Processing rm_id 379\n",
      "No model for rm_id 379, setting predicted_weight to 0\n",
      "Processing rm_id 380\n",
      "No model for rm_id 380, setting predicted_weight to 0\n",
      "Processing rm_id 381\n",
      "No model for rm_id 381, setting predicted_weight to 0\n",
      "Processing rm_id 383\n",
      "No model for rm_id 383, setting predicted_weight to 0\n",
      "Processing rm_id 386\n",
      "No model for rm_id 386, setting predicted_weight to 0\n",
      "Processing rm_id 387\n",
      "No model for rm_id 387, setting predicted_weight to 0\n",
      "Processing rm_id 388\n",
      "No model for rm_id 388, setting predicted_weight to 0\n",
      "Processing rm_id 389\n",
      "No model for rm_id 389, setting predicted_weight to 0\n",
      "Processing rm_id 390\n",
      "No model for rm_id 390, setting predicted_weight to 0\n",
      "Processing rm_id 1842\n",
      "No model for rm_id 1842, setting predicted_weight to 0\n",
      "Processing rm_id 1843\n",
      "No model for rm_id 1843, setting predicted_weight to 0\n",
      "Processing rm_id 1844\n",
      "No model for rm_id 1844, setting predicted_weight to 0\n",
      "Processing rm_id 1845\n",
      "No model for rm_id 1845, setting predicted_weight to 0\n",
      "Processing rm_id 1846\n",
      "No model for rm_id 1846, setting predicted_weight to 0\n",
      "Processing rm_id 1850\n",
      "No model for rm_id 1850, setting predicted_weight to 0\n",
      "Processing rm_id 1851\n",
      "No model for rm_id 1851, setting predicted_weight to 0\n",
      "Processing rm_id 1852\n",
      "No model for rm_id 1852, setting predicted_weight to 0\n",
      "Processing rm_id 1853\n",
      "No model for rm_id 1853, setting predicted_weight to 0\n",
      "Processing rm_id 1854\n",
      "No model for rm_id 1854, setting predicted_weight to 0\n",
      "Processing rm_id 1857\n",
      "No model for rm_id 1857, setting predicted_weight to 0\n",
      "Processing rm_id 1858\n",
      "No model for rm_id 1858, setting predicted_weight to 0\n",
      "Processing rm_id 1866\n",
      "No model for rm_id 1866, setting predicted_weight to 0\n",
      "Processing rm_id 1867\n",
      "No model for rm_id 1867, setting predicted_weight to 0\n",
      "Processing rm_id 1868\n",
      "No model for rm_id 1868, setting predicted_weight to 0\n",
      "Processing rm_id 1871\n",
      "No model for rm_id 1871, setting predicted_weight to 0\n",
      "Processing rm_id 1872\n",
      "No model for rm_id 1872, setting predicted_weight to 0\n",
      "Processing rm_id 1873\n",
      "No model for rm_id 1873, setting predicted_weight to 0\n",
      "Processing rm_id 1874\n",
      "No model for rm_id 1874, setting predicted_weight to 0\n",
      "Processing rm_id 1875\n",
      "No model for rm_id 1875, setting predicted_weight to 0\n",
      "Processing rm_id 1876\n",
      "No model for rm_id 1876, setting predicted_weight to 0\n",
      "Processing rm_id 1882\n",
      "No model for rm_id 1882, setting predicted_weight to 0\n",
      "Processing rm_id 1901\n",
      "No model for rm_id 1901, setting predicted_weight to 0\n",
      "Processing rm_id 1902\n",
      "No model for rm_id 1902, setting predicted_weight to 0\n",
      "Processing rm_id 1903\n",
      "No model for rm_id 1903, setting predicted_weight to 0\n",
      "Processing rm_id 1904\n",
      "No model for rm_id 1904, setting predicted_weight to 0\n",
      "Processing rm_id 1905\n",
      "No model for rm_id 1905, setting predicted_weight to 0\n",
      "Processing rm_id 1906\n",
      "No model for rm_id 1906, setting predicted_weight to 0\n",
      "Processing rm_id 1907\n",
      "No model for rm_id 1907, setting predicted_weight to 0\n",
      "Processing rm_id 1908\n",
      "No model for rm_id 1908, setting predicted_weight to 0\n",
      "Processing rm_id 1909\n",
      "No model for rm_id 1909, setting predicted_weight to 0\n",
      "Processing rm_id 1981\n",
      "No model for rm_id 1981, setting predicted_weight to 0\n",
      "Processing rm_id 1982\n",
      "No model for rm_id 1982, setting predicted_weight to 0\n",
      "Processing rm_id 2001\n",
      "No model for rm_id 2001, setting predicted_weight to 0\n",
      "Processing rm_id 2061\n",
      "No model for rm_id 2061, setting predicted_weight to 0\n",
      "Processing rm_id 2102\n",
      "No model for rm_id 2102, setting predicted_weight to 0\n",
      "Processing rm_id 2121\n",
      "Predicting 150 steps for rm_id 2121 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2122\n",
      "No model for rm_id 2122, setting predicted_weight to 0\n",
      "Processing rm_id 2123\n",
      "Predicting 150 steps for rm_id 2123 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2124\n",
      "Predicting 150 steps for rm_id 2124 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2125\n",
      "Predicting 150 steps for rm_id 2125 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2127\n",
      "No model for rm_id 2127, setting predicted_weight to 0\n",
      "Processing rm_id 2128\n",
      "No model for rm_id 2128, setting predicted_weight to 0\n",
      "Processing rm_id 2129\n",
      "Predicting 150 steps for rm_id 2129 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2130\n",
      "Predicting 150 steps for rm_id 2130 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2131\n",
      "Predicting 150 steps for rm_id 2131 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2132\n",
      "Predicting 150 steps for rm_id 2132 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2133\n",
      "Predicting 150 steps for rm_id 2133 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2134\n",
      "Predicting 150 steps for rm_id 2134 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2135\n",
      "Predicting 150 steps for rm_id 2135 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2138\n",
      "No model for rm_id 2138, setting predicted_weight to 0\n",
      "Processing rm_id 2139\n",
      "No model for rm_id 2139, setting predicted_weight to 0\n",
      "Processing rm_id 2140\n",
      "Predicting 150 steps for rm_id 2140 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2141\n",
      "No model for rm_id 2141, setting predicted_weight to 0\n",
      "Processing rm_id 2142\n",
      "Predicting 150 steps for rm_id 2142 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2143\n",
      "Predicting 150 steps for rm_id 2143 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2144\n",
      "Predicting 150 steps for rm_id 2144 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2145\n",
      "Predicting 150 steps for rm_id 2145 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2146\n",
      "No model for rm_id 2146, setting predicted_weight to 0\n",
      "Processing rm_id 2147\n",
      "Predicting 150 steps for rm_id 2147 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2148\n",
      "No model for rm_id 2148, setting predicted_weight to 0\n",
      "Processing rm_id 2149\n",
      "No model for rm_id 2149, setting predicted_weight to 0\n",
      "Processing rm_id 2150\n",
      "No model for rm_id 2150, setting predicted_weight to 0\n",
      "Processing rm_id 2151\n",
      "No model for rm_id 2151, setting predicted_weight to 0\n",
      "Processing rm_id 2152\n",
      "No model for rm_id 2152, setting predicted_weight to 0\n",
      "Processing rm_id 2153\n",
      "Predicting 150 steps for rm_id 2153 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2155\n",
      "No model for rm_id 2155, setting predicted_weight to 0\n",
      "Processing rm_id 2156\n",
      "No model for rm_id 2156, setting predicted_weight to 0\n",
      "Processing rm_id 2157\n",
      "No model for rm_id 2157, setting predicted_weight to 0\n",
      "Processing rm_id 2158\n",
      "No model for rm_id 2158, setting predicted_weight to 0\n",
      "Processing rm_id 2159\n",
      "No model for rm_id 2159, setting predicted_weight to 0\n",
      "Processing rm_id 2160\n",
      "Predicting 150 steps for rm_id 2160 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2161\n",
      "Predicting 150 steps for rm_id 2161 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2182\n",
      "No model for rm_id 2182, setting predicted_weight to 0\n",
      "Processing rm_id 2201\n",
      "No model for rm_id 2201, setting predicted_weight to 0\n",
      "Processing rm_id 2222\n",
      "No model for rm_id 2222, setting predicted_weight to 0\n",
      "Processing rm_id 2223\n",
      "No model for rm_id 2223, setting predicted_weight to 0\n",
      "Processing rm_id 2261\n",
      "No model for rm_id 2261, setting predicted_weight to 0\n",
      "Processing rm_id 2282\n",
      "No model for rm_id 2282, setting predicted_weight to 0\n",
      "Processing rm_id 2283\n",
      "No model for rm_id 2283, setting predicted_weight to 0\n",
      "Processing rm_id 2284\n",
      "Predicting 150 steps for rm_id 2284 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2285\n",
      "No model for rm_id 2285, setting predicted_weight to 0\n",
      "Processing rm_id 2302\n",
      "No model for rm_id 2302, setting predicted_weight to 0\n",
      "Processing rm_id 2304\n",
      "No model for rm_id 2304, setting predicted_weight to 0\n",
      "Processing rm_id 2322\n",
      "No model for rm_id 2322, setting predicted_weight to 0\n",
      "Processing rm_id 2323\n",
      "No model for rm_id 2323, setting predicted_weight to 0\n",
      "Processing rm_id 2341\n",
      "No model for rm_id 2341, setting predicted_weight to 0\n",
      "Processing rm_id 2343\n",
      "No model for rm_id 2343, setting predicted_weight to 0\n",
      "Processing rm_id 2344\n",
      "No model for rm_id 2344, setting predicted_weight to 0\n",
      "Processing rm_id 2345\n",
      "No model for rm_id 2345, setting predicted_weight to 0\n",
      "Processing rm_id 2347\n",
      "No model for rm_id 2347, setting predicted_weight to 0\n",
      "Processing rm_id 2348\n",
      "No model for rm_id 2348, setting predicted_weight to 0\n",
      "Processing rm_id 2362\n",
      "No model for rm_id 2362, setting predicted_weight to 0\n",
      "Processing rm_id 2363\n",
      "No model for rm_id 2363, setting predicted_weight to 0\n",
      "Processing rm_id 2364\n",
      "No model for rm_id 2364, setting predicted_weight to 0\n",
      "Processing rm_id 2365\n",
      "No model for rm_id 2365, setting predicted_weight to 0\n",
      "Processing rm_id 2401\n",
      "No model for rm_id 2401, setting predicted_weight to 0\n",
      "Processing rm_id 2402\n",
      "Predicting 150 steps for rm_id 2402 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2421\n",
      "No model for rm_id 2421, setting predicted_weight to 0\n",
      "Processing rm_id 2441\n",
      "No model for rm_id 2441, setting predicted_weight to 0\n",
      "Processing rm_id 2481\n",
      "No model for rm_id 2481, setting predicted_weight to 0\n",
      "Processing rm_id 2482\n",
      "Predicting 150 steps for rm_id 2482 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2521\n",
      "Predicting 150 steps for rm_id 2521 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2561\n",
      "Predicting 150 steps for rm_id 2561 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2601\n",
      "Predicting 150 steps for rm_id 2601 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2741\n",
      "Predicting 150 steps for rm_id 2741 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2742\n",
      "No model for rm_id 2742, setting predicted_weight to 0\n",
      "Processing rm_id 2761\n",
      "Predicting 150 steps for rm_id 2761 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2821\n",
      "No model for rm_id 2821, setting predicted_weight to 0\n",
      "Processing rm_id 2841\n",
      "No model for rm_id 2841, setting predicted_weight to 0\n",
      "Processing rm_id 2861\n",
      "No model for rm_id 2861, setting predicted_weight to 0\n",
      "Processing rm_id 2981\n",
      "Predicting 150 steps for rm_id 2981 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3005\n",
      "Predicting 150 steps for rm_id 3005 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3022\n",
      "No model for rm_id 3022, setting predicted_weight to 0\n",
      "Processing rm_id 3101\n",
      "Predicting 150 steps for rm_id 3101 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3121\n",
      "Predicting 150 steps for rm_id 3121 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3122\n",
      "Predicting 150 steps for rm_id 3122 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3123\n",
      "Predicting 150 steps for rm_id 3123 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3124\n",
      "Predicting 150 steps for rm_id 3124 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3125\n",
      "Predicting 150 steps for rm_id 3125 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3126\n",
      "Predicting 150 steps for rm_id 3126 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3142\n",
      "Predicting 150 steps for rm_id 3142 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3144\n",
      "No model for rm_id 3144, setting predicted_weight to 0\n",
      "Processing rm_id 3161\n",
      "Predicting 150 steps for rm_id 3161 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3162\n",
      "Predicting 150 steps for rm_id 3162 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3201\n",
      "No model for rm_id 3201, setting predicted_weight to 0\n",
      "Processing rm_id 3222\n",
      "Predicting 150 steps for rm_id 3222 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3241\n",
      "Predicting 150 steps for rm_id 3241 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3265\n",
      "Predicting 150 steps for rm_id 3265 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3282\n",
      "Predicting 150 steps for rm_id 3282 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3362\n",
      "Predicting 150 steps for rm_id 3362 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3381\n",
      "Predicting 150 steps for rm_id 3381 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3421\n",
      "Predicting 150 steps for rm_id 3421 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3441\n",
      "Predicting 150 steps for rm_id 3441 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3461\n",
      "No model for rm_id 3461, setting predicted_weight to 0\n",
      "Processing rm_id 3481\n",
      "Predicting 150 steps for rm_id 3481 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3501\n",
      "Predicting 150 steps for rm_id 3501 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3541\n",
      "Predicting 150 steps for rm_id 3541 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3581\n",
      "Predicting 150 steps for rm_id 3581 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3601\n",
      "Predicting 150 steps for rm_id 3601 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3621\n",
      "Predicting 150 steps for rm_id 3621 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3642\n",
      "Predicting 150 steps for rm_id 3642 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3701\n",
      "Predicting 150 steps for rm_id 3701 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3761\n",
      "Predicting 150 steps for rm_id 3761 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3762\n",
      "Predicting 150 steps for rm_id 3762 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3781\n",
      "Predicting 150 steps for rm_id 3781 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3802\n",
      "Predicting 150 steps for rm_id 3802 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3821\n",
      "Predicting 150 steps for rm_id 3821 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3841\n",
      "Predicting 150 steps for rm_id 3841 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3865\n",
      "Predicting 150 steps for rm_id 3865 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3883\n",
      "Predicting 150 steps for rm_id 3883 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3901\n",
      "Predicting 150 steps for rm_id 3901 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3921\n",
      "Predicting 150 steps for rm_id 3921 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3941\n",
      "Predicting 150 steps for rm_id 3941 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 4021\n",
      "Predicting 150 steps for rm_id 4021 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 4044\n",
      "Predicting 150 steps for rm_id 4044 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 4081\n",
      "Predicting 150 steps for rm_id 4081 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 4101\n",
      "Predicting 150 steps for rm_id 4101 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 4161\n",
      "Predicting 150 steps for rm_id 4161 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 4222\n",
      "No model for rm_id 4222, setting predicted_weight to 0\n",
      "Processing rm_id 4263\n",
      "No model for rm_id 4263, setting predicted_weight to 0\n",
      "Processing rm_id 4302\n",
      "No model for rm_id 4302, setting predicted_weight to 0\n",
      "Processing rm_id 4343\n",
      "No model for rm_id 4343, setting predicted_weight to 0\n",
      "Processing rm_id 4381\n",
      "No model for rm_id 4381, setting predicted_weight to 0\n",
      "Processing rm_id 4401\n",
      "No model for rm_id 4401, setting predicted_weight to 0\n",
      "Processing rm_id 4441\n",
      "No model for rm_id 4441, setting predicted_weight to 0\n",
      "Processing rm_id 4443\n",
      "No model for rm_id 4443, setting predicted_weight to 0\n",
      "Processing rm_id 4461\n",
      "No model for rm_id 4461, setting predicted_weight to 0\n",
      "Processing rm_id 4462\n",
      "No model for rm_id 4462, setting predicted_weight to 0\n",
      "Processing rm_id 4463\n",
      "No model for rm_id 4463, setting predicted_weight to 0\n",
      "Processing rm_id 4481\n",
      "No model for rm_id 4481, setting predicted_weight to 0\n",
      "Processing rm_id 4501\n",
      "No model for rm_id 4501, setting predicted_weight to 0\n"
     ]
    }
   ],
   "source": [
    "prediction_mapping = pd.read_csv(\"./data/prediction_mapping.csv\")\n",
    "prediction_mapping[\"forecast_start_date\"] = (\n",
    "    pd.to_datetime(prediction_mapping[\"forecast_start_date\"], utc=True)\n",
    "    .dt.tz_localize(None)\n",
    "    .dt.normalize()\n",
    ")\n",
    "prediction_mapping[\"forecast_end_date\"] = (\n",
    "    pd.to_datetime(prediction_mapping[\"forecast_end_date\"], utc=True)\n",
    "    .dt.tz_localize(None)\n",
    "    .dt.normalize()\n",
    ")\n",
    "prediction_mapping = prediction_mapping.sort_values([\"rm_id\", \"forecast_end_date\"])\n",
    "max_date = pd.Timestamp(\"2025-05-31\")\n",
    "lst = []\n",
    "for rm_id, group in prediction_mapping.groupby(\"rm_id\"):\n",
    "    print(f\"Processing rm_id {rm_id}\")\n",
    "    if rm_id not in model_dict:\n",
    "        print(f\"No model for rm_id {rm_id}, setting predicted_weight to 0\")\n",
    "        group[\"predicted_weight\"] = 0\n",
    "    else:\n",
    "\n",
    "        last_train = series_dict[rm_id].time_index[-1]\n",
    "        n_steps = (max_date - last_train).days - 1\n",
    "        print(\n",
    "            f\"Predicting {n_steps} steps for rm_id {rm_id} because last known date is {last_train}\"\n",
    "        )\n",
    "        out = model_dict[rm_id].predict(n_steps, series=series_dict[rm_id])\n",
    "        cum_out = scaler_dict[rm_id].inverse_transform(out).cumsum()\n",
    "        cum_out = cum_out.values().clip(min=0)\n",
    "        cum_out[cum_out < 100] = 0  # set predictions below 100 to 0\n",
    "\n",
    "        group[\"predicted_weight\"] = cum_out\n",
    "    lst.append(group)\n",
    "\n",
    "df_final = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission_path = f\"./data/submission/submission_{timestamp}.csv\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(\"./data/submission/\"):\n",
    "    os.makedirs(\"./data/submission/\")\n",
    "\n",
    "df_final[[\"ID\", \"predicted_weight\"]].to_csv(submission_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
