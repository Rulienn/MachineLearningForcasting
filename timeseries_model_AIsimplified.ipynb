{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d2bfc4-78b1-4547-92b6-52871477e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theoc\\AppData\\Local\\Temp\\ipykernel_4876\\3894692812.py:115: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(cum=g[\"net_weight\"].cumsum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier de soumission généré : ./submissions/submission_timeseries.csv\n",
      "   ID  predicted_weight\n",
      "0   1               0.0\n",
      "1   2               0.0\n",
      "2   3               0.0\n",
      "3   4               0.0\n",
      "4   5               0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Config\n",
    "# -----------------------------\n",
    "start_date = \"2012-01-01\"   # on coupe avant 2012\n",
    "forecast_start = pd.Timestamp(\"2025-01-01\")\n",
    "forecast_end   = pd.Timestamp(\"2025-05-31\")\n",
    "seasonality = 7\n",
    "Positive_Deliveries = True\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Charger et nettoyer\n",
    "# -----------------------------\n",
    "receivals = pd.read_csv(\"./data/kernel/receivals.csv\")\n",
    "receivals = receivals.dropna(subset=[\"net_weight\"])\n",
    "receivals = receivals[receivals[\"net_weight\"] > 0]\n",
    "\n",
    "receivals[\"date_arrival\"] = (\n",
    "    pd.to_datetime(receivals[\"date_arrival\"], utc=True)\n",
    "      .dt.tz_localize(None)\n",
    "      .dt.normalize()\n",
    ")\n",
    "\n",
    "# on enlève les données < 2012\n",
    "receivals = receivals[receivals[\"date_arrival\"] >= pd.Timestamp(start_date)].reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Agrégation journalière\n",
    "# -----------------------------\n",
    "daily = (\n",
    "    receivals.groupby([\"rm_id\",\"date_arrival\"], as_index=False)\n",
    "             .agg(net_weight=(\"net_weight\",\"sum\"))\n",
    "             .rename(columns={\"date_arrival\":\"date\"})\n",
    "             .sort_values([\"rm_id\",\"date\"])\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Filtrer les séries trop rares\n",
    "# -----------------------------\n",
    "stats = (\n",
    "    daily.groupby(\"rm_id\")\n",
    "         .agg(last_delivery=(\"date\",\"max\"),\n",
    "              total_deliveries=(\"date\",\"count\"))\n",
    ")\n",
    "cutoff = pd.Timestamp(\"2024-12-31\") - pd.DateOffset(years=5)\n",
    "rare_rm_id = stats.index[(stats[\"last_delivery\"] <= cutoff) & (stats[\"total_deliveries\"] <= 3)]\n",
    "daily = daily[~daily[\"rm_id\"].isin(rare_rm_id)].reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Reindexer sur grille complète\n",
    "# -----------------------------\n",
    "full_start = daily[\"date\"].min()\n",
    "full_end   = pd.Timestamp(\"2024-12-31\")\n",
    "rm_ids = pd.Index(daily[\"rm_id\"].unique(), name=\"rm_id\")\n",
    "calendar = pd.date_range(full_start, full_end, freq=\"D\", name=\"date\")\n",
    "full_idx = pd.MultiIndex.from_product([rm_ids, calendar], names=[\"rm_id\",\"date\"])\n",
    "\n",
    "daily = (\n",
    "    daily.set_index([\"rm_id\",\"date\"])[\"net_weight\"]\n",
    "         .reindex(full_idx, fill_value=0)\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Prévisions Holt-Winters par série\n",
    "# -----------------------------\n",
    "predictions = []\n",
    "for rm in daily[\"rm_id\"].unique():\n",
    "    series = (\n",
    "        daily.loc[daily[\"rm_id\"]==rm, [\"date\",\"net_weight\"]]\n",
    "             .set_index(\"date\")[\"net_weight\"]\n",
    "             .asfreq(\"D\")\n",
    "    )\n",
    "    # Option : démarrer à la première livraison >0\n",
    "    pos_idx = series.index[series.gt(0)]\n",
    "    if len(pos_idx)>0:\n",
    "        first_dt = pos_idx[0]\n",
    "        series = series.loc[first_dt:]\n",
    "\n",
    "    # Fit Holt-Winters\n",
    "    try:\n",
    "        model = ExponentialSmoothing(\n",
    "            series,\n",
    "            trend=None,\n",
    "            seasonal=\"add\",\n",
    "            seasonal_periods=seasonality,\n",
    "            initialization_method=\"estimated\"\n",
    "        ).fit(optimized=True)\n",
    "        fc = model.predict(start=forecast_start, end=forecast_end)\n",
    "    except Exception:\n",
    "        # fallback : tout plat\n",
    "        fc = pd.Series(0.0, index=pd.date_range(forecast_start, forecast_end, freq=\"D\"))\n",
    "\n",
    "    pred = (\n",
    "        fc.rename(\"net_weight\")\n",
    "          .reset_index()\n",
    "          .rename(columns={\"index\":\"date\"})\n",
    "    )\n",
    "    if Positive_Deliveries:\n",
    "        pred[\"net_weight\"] = pred[\"net_weight\"].clip(lower=0)\n",
    "    pred[\"rm_id\"] = rm\n",
    "    predictions.append(pred)\n",
    "\n",
    "df_forecast = pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Construire df_final avec cumuls\n",
    "# -----------------------------\n",
    "df_cum = (\n",
    "    df_forecast.sort_values([\"rm_id\",\"date\"])\n",
    "               .groupby(\"rm_id\", as_index=False)\n",
    "               .apply(lambda g: g.assign(cum=g[\"net_weight\"].cumsum()))\n",
    "               .reset_index(drop=True)[[\"rm_id\",\"date\",\"cum\"]]\n",
    ")\n",
    "df_cum[\"cum\"] = df_cum[\"cum\"].clip(lower=0)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Charger mapping et générer soumission\n",
    "# -----------------------------\n",
    "ids = pd.read_csv(\"./data/prediction_mapping.csv\")\n",
    "ids[\"forecast_start_date\"] = pd.to_datetime(ids[\"forecast_start_date\"])\n",
    "ids[\"forecast_end_date\"] = pd.to_datetime(ids[\"forecast_end_date\"])\n",
    "ids[\"rm_id\"] = pd.to_numeric(ids[\"rm_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "ids = ids.rename(columns={\"forecast_end_date\":\"date\"})\n",
    "\n",
    "out = (\n",
    "    ids.merge(df_cum, on=[\"rm_id\",\"date\"], how=\"left\")\n",
    "       .assign(cum=lambda d: d[\"cum\"].fillna(0))\n",
    "       .sort_values([\"ID\"])\n",
    "       .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "submission = (\n",
    "    out[[\"ID\",\"cum\"]]\n",
    "      .rename(columns={\"cum\":\"predicted_weight\"})\n",
    "      .fillna({\"predicted_weight\":0})\n",
    "      .astype({\"ID\":int,\"predicted_weight\":float})\n",
    ")\n",
    "\n",
    "submission.to_csv(\"./submissions/submission_timeseries.csv\", index=False)\n",
    "print(\"✅ Fichier de soumission généré : ./submissions/submission_timeseries.csv\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
