{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "467b192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: darts in ./.venv/lib/python3.12/site-packages (0.38.0)\n",
      "Requirement already satisfied: holidays>=0.11.1 in ./.venv/lib/python3.12/site-packages (from darts) (0.81)\n",
      "Requirement already satisfied: joblib>=0.16.0 in ./.venv/lib/python3.12/site-packages (from darts) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.12/site-packages (from darts) (3.10.6)\n",
      "Requirement already satisfied: narwhals>=1.25.1 in ./.venv/lib/python3.12/site-packages (from darts) (2.7.0)\n",
      "Requirement already satisfied: nfoursid>=1.0.0 in ./.venv/lib/python3.12/site-packages (from darts) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.3.3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in ./.venv/lib/python3.12/site-packages (from darts) (2.3.3)\n",
      "Requirement already satisfied: pyod>=0.9.5 in ./.venv/lib/python3.12/site-packages (from darts) (2.0.5)\n",
      "Requirement already satisfied: requests>=2.22.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.32.5)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in ./.venv/lib/python3.12/site-packages (from darts) (1.7.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.venv/lib/python3.12/site-packages (from darts) (1.16.2)\n",
      "Requirement already satisfied: shap>=0.40.0 in ./.venv/lib/python3.12/site-packages (from darts) (0.48.0)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in ./.venv/lib/python3.12/site-packages (from darts) (0.14.5)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in ./.venv/lib/python3.12/site-packages (from darts) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from darts) (4.15.0)\n",
      "Requirement already satisfied: xarray>=0.17.0 in ./.venv/lib/python3.12/site-packages (from darts) (2025.9.1)\n",
      "Requirement already satisfied: pytorch-lightning<2.5.3,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.5.2)\n",
      "Requirement already satisfied: tensorboardX>=2.1 in ./.venv/lib/python3.12/site-packages (from darts) (2.6.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.12/site-packages (from darts) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.12/site-packages (from holidays>=0.11.1->darts) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (3.2.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.5->darts) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.5->darts) (2025.2)\n",
      "Requirement already satisfied: numba>=0.51 in ./.venv/lib/python3.12/site-packages (from pyod>=0.9.5->darts) (0.62.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./.venv/lib/python3.12/site-packages (from pytorch-lightning<2.5.3,>=2.0.0->darts) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (2025.9.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./.venv/lib/python3.12/site-packages (from pytorch-lightning<2.5.3,>=2.0.0->darts) (1.8.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in ./.venv/lib/python3.12/site-packages (from pytorch-lightning<2.5.3,>=2.0.0->darts) (0.15.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.22.0->darts) (2025.10.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.6.0->darts) (3.6.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in ./.venv/lib/python3.12/site-packages (from shap>=0.40.0->darts) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.12/site-packages (from shap>=0.40.0->darts) (3.1.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in ./.venv/lib/python3.12/site-packages (from statsmodels>=0.14.0->darts) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in ./.venv/lib/python3.12/site-packages (from tensorboardX>=2.1->darts) (6.32.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.19.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.1.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (3.12.15)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in ./.venv/lib/python3.12/site-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.45.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil->holidays>=0.11.1->darts) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->darts) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->darts) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.3,>=2.0.0->darts) (1.21.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catboost in ./.venv/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from catboost) (3.10.6)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./.venv/lib/python3.12/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.venv/lib/python3.12/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from catboost) (1.16.2)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.12/site-packages (from catboost) (6.3.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.12/site-packages (from plotly->catboost) (2.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install darts\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "20dfa585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from darts import TimeSeries\n",
    "from darts.models import CatBoostModel\n",
    "import pandas as pd\n",
    "import os\n",
    "import kaggle_metric\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8571ae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date_arrival",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "rm_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "net_weight",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "92714c29-02bc-4cf0-9c4b-23d9399d6e44",
       "rows": [
        [
         "0",
         "2004-06-15 00:00:00",
         "342",
         "0.0"
        ],
        [
         "1",
         "2004-06-16 00:00:00",
         "342",
         "0.0"
        ],
        [
         "2",
         "2004-06-17 00:00:00",
         "342",
         "0.0"
        ],
        [
         "3",
         "2004-06-18 00:00:00",
         "342",
         "0.0"
        ],
        [
         "4",
         "2004-06-19 00:00:00",
         "342",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_arrival</th>\n",
       "      <th>rm_id</th>\n",
       "      <th>net_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-06-16</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-06-17</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-06-18</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-06-19</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_arrival  rm_id  net_weight\n",
       "0   2004-06-15    342         0.0\n",
       "1   2004-06-16    342         0.0\n",
       "2   2004-06-17    342         0.0\n",
       "3   2004-06-18    342         0.0\n",
       "4   2004-06-19    342         0.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.create_df('./data/kernel/receivals.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "80d1da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_lst = TimeSeries.from_group_dataframe(df, 'rm_id', 'date_arrival','net_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6269eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {}\n",
    "train_dict = {}\n",
    "val_dict = {}\n",
    "for i in range(len(series_lst)):\n",
    "    train_i, val_i = series_lst[i].split_after(0.8)\n",
    "    \n",
    "    rm_id = series_lst[i].static_covariates[\"rm_id\"] if \"rm_id\" in series_lst[i].static_covariates else None\n",
    "    series_dict[rm_id.values[0]] = series_lst[i]\n",
    "    train_dict[rm_id.values[0]] = train_i\n",
    "    val_dict[rm_id.values[0]] = val_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5e371019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for rm_id: 342.0\n",
      "Error training model for rm_id 342.0: catboost/libs/metrics/metric.cpp:6935: All train targets are equal\n",
      "Training model for rm_id: 343.0\n",
      "Training model for rm_id: 345.0\n",
      "Training model for rm_id: 346.0\n",
      "Training model for rm_id: 347.0\n",
      "Training model for rm_id: 348.0\n",
      "Training model for rm_id: 353.0\n",
      "Training model for rm_id: 354.0\n",
      "Training model for rm_id: 355.0\n",
      "Training model for rm_id: 357.0\n",
      "Training model for rm_id: 358.0\n",
      "Training model for rm_id: 360.0\n",
      "Training model for rm_id: 362.0\n",
      "Training model for rm_id: 364.0\n",
      "Training model for rm_id: 365.0\n",
      "Training model for rm_id: 366.0\n",
      "Training model for rm_id: 367.0\n",
      "Training model for rm_id: 368.0\n",
      "Training model for rm_id: 369.0\n",
      "Training model for rm_id: 374.0\n",
      "Training model for rm_id: 375.0\n",
      "Training model for rm_id: 378.0\n",
      "Training model for rm_id: 379.0\n",
      "Training model for rm_id: 380.0\n",
      "Training model for rm_id: 381.0\n",
      "Training model for rm_id: 383.0\n",
      "Training model for rm_id: 386.0\n",
      "Training model for rm_id: 387.0\n",
      "Training model for rm_id: 388.0\n",
      "Training model for rm_id: 389.0\n",
      "Training model for rm_id: 390.0\n",
      "Training model for rm_id: 1842.0\n",
      "Training model for rm_id: 1843.0\n",
      "Training model for rm_id: 1844.0\n",
      "Training model for rm_id: 1845.0\n",
      "Training model for rm_id: 1846.0\n",
      "Training model for rm_id: 1850.0\n",
      "Training model for rm_id: 1851.0\n",
      "Training model for rm_id: 1852.0\n",
      "Training model for rm_id: 1853.0\n",
      "Training model for rm_id: 1854.0\n",
      "Training model for rm_id: 1857.0\n",
      "Training model for rm_id: 1858.0\n",
      "Training model for rm_id: 1866.0\n",
      "Training model for rm_id: 1867.0\n",
      "Training model for rm_id: 1868.0\n",
      "Training model for rm_id: 1871.0\n",
      "Training model for rm_id: 1872.0\n",
      "Training model for rm_id: 1873.0\n",
      "Training model for rm_id: 1874.0\n",
      "Training model for rm_id: 1875.0\n",
      "Training model for rm_id: 1876.0\n",
      "Training model for rm_id: 1882.0\n",
      "Training model for rm_id: 1901.0\n",
      "Training model for rm_id: 1902.0\n",
      "Training model for rm_id: 1903.0\n",
      "Training model for rm_id: 1904.0\n",
      "Training model for rm_id: 1905.0\n",
      "Training model for rm_id: 1906.0\n",
      "Training model for rm_id: 1907.0\n",
      "Training model for rm_id: 1908.0\n",
      "Training model for rm_id: 1909.0\n",
      "Training model for rm_id: 1981.0\n",
      "Training model for rm_id: 1982.0\n",
      "Training model for rm_id: 2001.0\n",
      "Training model for rm_id: 2061.0\n",
      "Training model for rm_id: 2102.0\n",
      "Training model for rm_id: 2121.0\n",
      "Training model for rm_id: 2122.0\n",
      "Training model for rm_id: 2123.0\n",
      "Training model for rm_id: 2124.0\n",
      "Training model for rm_id: 2125.0\n",
      "Training model for rm_id: 2127.0\n",
      "Training model for rm_id: 2128.0\n",
      "Training model for rm_id: 2129.0\n",
      "Training model for rm_id: 2130.0\n",
      "Training model for rm_id: 2131.0\n",
      "Training model for rm_id: 2132.0\n",
      "Training model for rm_id: 2133.0\n",
      "Training model for rm_id: 2134.0\n",
      "Training model for rm_id: 2135.0\n",
      "Training model for rm_id: 2138.0\n",
      "Training model for rm_id: 2139.0\n",
      "Training model for rm_id: 2140.0\n",
      "Training model for rm_id: 2141.0\n",
      "Training model for rm_id: 2142.0\n",
      "Training model for rm_id: 2143.0\n",
      "Training model for rm_id: 2144.0\n",
      "Training model for rm_id: 2145.0\n",
      "Training model for rm_id: 2146.0\n",
      "Training model for rm_id: 2147.0\n",
      "Training model for rm_id: 2148.0\n",
      "Training model for rm_id: 2149.0\n",
      "Training model for rm_id: 2150.0\n",
      "Training model for rm_id: 2151.0\n",
      "Training model for rm_id: 2152.0\n",
      "Training model for rm_id: 2153.0\n",
      "Training model for rm_id: 2155.0\n",
      "Training model for rm_id: 2156.0\n",
      "Training model for rm_id: 2157.0\n",
      "Training model for rm_id: 2158.0\n",
      "Training model for rm_id: 2159.0\n",
      "Training model for rm_id: 2160.0\n",
      "Training model for rm_id: 2161.0\n",
      "Training model for rm_id: 2182.0\n",
      "Training model for rm_id: 2201.0\n",
      "Training model for rm_id: 2222.0\n",
      "Training model for rm_id: 2223.0\n",
      "Training model for rm_id: 2261.0\n",
      "Training model for rm_id: 2282.0\n",
      "Training model for rm_id: 2283.0\n",
      "Training model for rm_id: 2284.0\n",
      "Training model for rm_id: 2285.0\n",
      "Training model for rm_id: 2302.0\n",
      "Training model for rm_id: 2304.0\n",
      "Training model for rm_id: 2322.0\n",
      "Training model for rm_id: 2323.0\n",
      "Training model for rm_id: 2341.0\n",
      "Training model for rm_id: 2343.0\n",
      "Training model for rm_id: 2344.0\n",
      "Training model for rm_id: 2345.0\n",
      "Training model for rm_id: 2347.0\n",
      "Training model for rm_id: 2348.0\n",
      "Training model for rm_id: 2362.0\n",
      "Training model for rm_id: 2363.0\n",
      "Training model for rm_id: 2364.0\n",
      "Training model for rm_id: 2365.0\n",
      "Training model for rm_id: 2401.0\n",
      "Training model for rm_id: 2402.0\n",
      "Training model for rm_id: 2421.0\n",
      "Training model for rm_id: 2441.0\n",
      "Training model for rm_id: 2481.0\n",
      "Training model for rm_id: 2482.0\n",
      "Training model for rm_id: 2521.0\n",
      "Training model for rm_id: 2561.0\n",
      "Training model for rm_id: 2601.0\n",
      "Training model for rm_id: 2741.0\n",
      "Training model for rm_id: 2742.0\n",
      "Training model for rm_id: 2761.0\n",
      "Training model for rm_id: 2821.0\n",
      "Training model for rm_id: 2841.0\n",
      "Training model for rm_id: 2861.0\n",
      "Training model for rm_id: 2981.0\n",
      "Training model for rm_id: 3005.0\n",
      "Training model for rm_id: 3022.0\n",
      "Training model for rm_id: 3101.0\n",
      "Training model for rm_id: 3121.0\n",
      "Training model for rm_id: 3122.0\n",
      "Training model for rm_id: 3123.0\n",
      "Training model for rm_id: 3124.0\n",
      "Training model for rm_id: 3125.0\n",
      "Training model for rm_id: 3126.0\n",
      "Training model for rm_id: 3142.0\n",
      "Training model for rm_id: 3144.0\n",
      "Training model for rm_id: 3161.0\n",
      "Training model for rm_id: 3162.0\n",
      "Training model for rm_id: 3201.0\n",
      "Error training model for rm_id 3201.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3222.0\n",
      "Error training model for rm_id 3222.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3241.0\n",
      "Error training model for rm_id 3241.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3265.0\n",
      "Error training model for rm_id 3265.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3282.0\n",
      "Error training model for rm_id 3282.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3362.0\n",
      "Error training model for rm_id 3362.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3381.0\n",
      "Error training model for rm_id 3381.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3421.0\n",
      "Error training model for rm_id 3421.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3441.0\n",
      "Error training model for rm_id 3441.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3461.0\n",
      "Error training model for rm_id 3461.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3481.0\n",
      "Error training model for rm_id 3481.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3501.0\n",
      "Error training model for rm_id 3501.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3541.0\n",
      "Error training model for rm_id 3541.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3581.0\n",
      "Error training model for rm_id 3581.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3601.0\n",
      "Error training model for rm_id 3601.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3621.0\n",
      "Error training model for rm_id 3621.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3642.0\n",
      "Error training model for rm_id 3642.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3701.0\n",
      "Error training model for rm_id 3701.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3761.0\n",
      "Error training model for rm_id 3761.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3762.0\n",
      "Error training model for rm_id 3762.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3781.0\n",
      "Error training model for rm_id 3781.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3802.0\n",
      "Error training model for rm_id 3802.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3821.0\n",
      "Error training model for rm_id 3821.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3841.0\n",
      "Error training model for rm_id 3841.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3865.0\n",
      "Error training model for rm_id 3865.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3883.0\n",
      "Error training model for rm_id 3883.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3901.0\n",
      "Error training model for rm_id 3901.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3921.0\n",
      "Error training model for rm_id 3921.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 3941.0\n",
      "Error training model for rm_id 3941.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4021.0\n",
      "Error training model for rm_id 4021.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4044.0\n",
      "Error training model for rm_id 4044.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4081.0\n",
      "Error training model for rm_id 4081.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4101.0\n",
      "Error training model for rm_id 4101.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4161.0\n",
      "Error training model for rm_id 4161.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4222.0\n",
      "Error training model for rm_id 4222.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4263.0\n",
      "Error training model for rm_id 4263.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4302.0\n",
      "Error training model for rm_id 4302.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4343.0\n",
      "Error training model for rm_id 4343.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4381.0\n",
      "Error training model for rm_id 4381.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4401.0\n",
      "Error training model for rm_id 4401.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4441.0\n",
      "Error training model for rm_id 4441.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4443.0\n",
      "Error training model for rm_id 4443.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4461.0\n",
      "Error training model for rm_id 4461.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4462.0\n",
      "Error training model for rm_id 4462.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4463.0\n",
      "Error training model for rm_id 4463.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4481.0\n",
      "Error training model for rm_id 4481.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Training model for rm_id: 4501.0\n",
      "Error training model for rm_id 4501.0: catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
      "Validation score: 1070586.3530345403\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "loss = []\n",
    "\n",
    "lst = []\n",
    "for key in train_dict:\n",
    "    print(f\"Training model for rm_id: {key}\")\n",
    "    train_values = train_dict[key].values()\n",
    "    model = CatBoostModel(lags=30, use_static_covariates=False, random_state=42)\n",
    "    try:\n",
    "        model.fit(train_dict[key])\n",
    "        model_dict[key] = model\n",
    "        out = model_dict[key].predict(len(val_dict[key]), series=train_dict[key])\n",
    "        actual_steps = out.values().clip(min=0)\n",
    "        actual_steps = actual_steps.cumsum()\n",
    "        actual_steps[actual_steps < 100] = 0\n",
    "\n",
    "        # Store predictions and actual values in a dataframe\n",
    "        df_eval = pd.DataFrame({\n",
    "            'predicted_weight': actual_steps.flatten(),\n",
    "            'weight': val_dict[key].values().flatten()\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        df_eval = pd.DataFrame({\n",
    "            'predicted_weight': [0]*len(val_dict[key]),\n",
    "            'weight': val_dict[key].values().flatten()\n",
    "        })\n",
    "        print(f\"Error training model for rm_id {key}: {e}\")\n",
    "\n",
    "    lst.append(df_eval)\n",
    "\n",
    "df_eval = pd.concat(lst).reset_index(drop=True)\n",
    "df_eval['ID'] = df_eval.index\n",
    "score = kaggle_metric.score(df_eval[['ID', 'weight']], df_eval[['ID', 'predicted_weight']])\n",
    "print(f\"Validation score: {score}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "729331cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rm_id 342\n",
      "No model for rm_id 342, setting predicted_weight to 0\n",
      "Processing rm_id 343\n",
      "Predicting 150 steps for rm_id 343 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 345\n",
      "Predicting 150 steps for rm_id 345 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 346\n",
      "Predicting 150 steps for rm_id 346 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 347\n",
      "Predicting 150 steps for rm_id 347 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 348\n",
      "Predicting 150 steps for rm_id 348 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 353\n",
      "Predicting 150 steps for rm_id 353 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 354\n",
      "Predicting 150 steps for rm_id 354 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 355\n",
      "Predicting 150 steps for rm_id 355 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 357\n",
      "Predicting 150 steps for rm_id 357 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 358\n",
      "Predicting 150 steps for rm_id 358 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 360\n",
      "Predicting 150 steps for rm_id 360 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 362\n",
      "Predicting 150 steps for rm_id 362 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 364\n",
      "Predicting 150 steps for rm_id 364 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 365\n",
      "Predicting 150 steps for rm_id 365 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 366\n",
      "Predicting 150 steps for rm_id 366 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 367\n",
      "Predicting 150 steps for rm_id 367 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 368\n",
      "Predicting 150 steps for rm_id 368 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 369\n",
      "Predicting 150 steps for rm_id 369 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 374\n",
      "Predicting 150 steps for rm_id 374 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 375\n",
      "Predicting 150 steps for rm_id 375 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 378\n",
      "Predicting 150 steps for rm_id 378 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 379\n",
      "Predicting 150 steps for rm_id 379 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 380\n",
      "Predicting 150 steps for rm_id 380 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 381\n",
      "Predicting 150 steps for rm_id 381 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 383\n",
      "Predicting 150 steps for rm_id 383 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 386\n",
      "Predicting 150 steps for rm_id 386 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 387\n",
      "Predicting 150 steps for rm_id 387 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 388\n",
      "Predicting 150 steps for rm_id 388 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 389\n",
      "Predicting 150 steps for rm_id 389 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 390\n",
      "Predicting 150 steps for rm_id 390 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1842\n",
      "Predicting 150 steps for rm_id 1842 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1843\n",
      "Predicting 150 steps for rm_id 1843 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1844\n",
      "Predicting 150 steps for rm_id 1844 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1845\n",
      "Predicting 150 steps for rm_id 1845 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1846\n",
      "Predicting 150 steps for rm_id 1846 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1850\n",
      "Predicting 150 steps for rm_id 1850 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1851\n",
      "Predicting 150 steps for rm_id 1851 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1852\n",
      "Predicting 150 steps for rm_id 1852 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1853\n",
      "Predicting 150 steps for rm_id 1853 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1854\n",
      "Predicting 150 steps for rm_id 1854 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1857\n",
      "Predicting 150 steps for rm_id 1857 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1858\n",
      "Predicting 150 steps for rm_id 1858 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1866\n",
      "Predicting 150 steps for rm_id 1866 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1867\n",
      "Predicting 150 steps for rm_id 1867 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1868\n",
      "Predicting 150 steps for rm_id 1868 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1871\n",
      "Predicting 150 steps for rm_id 1871 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1872\n",
      "Predicting 150 steps for rm_id 1872 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1873\n",
      "Predicting 150 steps for rm_id 1873 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1874\n",
      "Predicting 150 steps for rm_id 1874 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1875\n",
      "Predicting 150 steps for rm_id 1875 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1876\n",
      "Predicting 150 steps for rm_id 1876 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1882\n",
      "Predicting 150 steps for rm_id 1882 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1901\n",
      "Predicting 150 steps for rm_id 1901 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1902\n",
      "Predicting 150 steps for rm_id 1902 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1903\n",
      "Predicting 150 steps for rm_id 1903 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1904\n",
      "Predicting 150 steps for rm_id 1904 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1905\n",
      "Predicting 150 steps for rm_id 1905 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1906\n",
      "Predicting 150 steps for rm_id 1906 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1907\n",
      "Predicting 150 steps for rm_id 1907 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1908\n",
      "Predicting 150 steps for rm_id 1908 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1909\n",
      "Predicting 150 steps for rm_id 1909 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1981\n",
      "Predicting 150 steps for rm_id 1981 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 1982\n",
      "Predicting 150 steps for rm_id 1982 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2001\n",
      "Predicting 150 steps for rm_id 2001 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2061\n",
      "Predicting 150 steps for rm_id 2061 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2102\n",
      "Predicting 150 steps for rm_id 2102 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2121\n",
      "Predicting 150 steps for rm_id 2121 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2122\n",
      "Predicting 150 steps for rm_id 2122 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2123\n",
      "Predicting 150 steps for rm_id 2123 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2124\n",
      "Predicting 150 steps for rm_id 2124 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2125\n",
      "Predicting 150 steps for rm_id 2125 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2127\n",
      "Predicting 150 steps for rm_id 2127 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2128\n",
      "Predicting 150 steps for rm_id 2128 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2129\n",
      "Predicting 150 steps for rm_id 2129 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2130\n",
      "Predicting 150 steps for rm_id 2130 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2131\n",
      "Predicting 150 steps for rm_id 2131 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2132\n",
      "Predicting 150 steps for rm_id 2132 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2133\n",
      "Predicting 150 steps for rm_id 2133 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2134\n",
      "Predicting 150 steps for rm_id 2134 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2135\n",
      "Predicting 150 steps for rm_id 2135 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2138\n",
      "Predicting 150 steps for rm_id 2138 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2139\n",
      "Predicting 150 steps for rm_id 2139 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2140\n",
      "Predicting 150 steps for rm_id 2140 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2141\n",
      "Predicting 150 steps for rm_id 2141 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2142\n",
      "Predicting 150 steps for rm_id 2142 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2143\n",
      "Predicting 150 steps for rm_id 2143 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2144\n",
      "Predicting 150 steps for rm_id 2144 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2145\n",
      "Predicting 150 steps for rm_id 2145 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2146\n",
      "Predicting 150 steps for rm_id 2146 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2147\n",
      "Predicting 150 steps for rm_id 2147 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2148\n",
      "Predicting 150 steps for rm_id 2148 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2149\n",
      "Predicting 150 steps for rm_id 2149 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2150\n",
      "Predicting 150 steps for rm_id 2150 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2151\n",
      "Predicting 150 steps for rm_id 2151 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2152\n",
      "Predicting 150 steps for rm_id 2152 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2153\n",
      "Predicting 150 steps for rm_id 2153 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2155\n",
      "Predicting 150 steps for rm_id 2155 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2156\n",
      "Predicting 150 steps for rm_id 2156 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2157\n",
      "Predicting 150 steps for rm_id 2157 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2158\n",
      "Predicting 150 steps for rm_id 2158 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2159\n",
      "Predicting 150 steps for rm_id 2159 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2160\n",
      "Predicting 150 steps for rm_id 2160 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2161\n",
      "Predicting 150 steps for rm_id 2161 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2182\n",
      "Predicting 150 steps for rm_id 2182 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2201\n",
      "Predicting 150 steps for rm_id 2201 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2222\n",
      "Predicting 150 steps for rm_id 2222 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2223\n",
      "Predicting 150 steps for rm_id 2223 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2261\n",
      "Predicting 150 steps for rm_id 2261 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2282\n",
      "Predicting 150 steps for rm_id 2282 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2283\n",
      "Predicting 150 steps for rm_id 2283 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2284\n",
      "Predicting 150 steps for rm_id 2284 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2285\n",
      "Predicting 150 steps for rm_id 2285 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2302\n",
      "Predicting 150 steps for rm_id 2302 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2304\n",
      "Predicting 150 steps for rm_id 2304 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2322\n",
      "Predicting 150 steps for rm_id 2322 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2323\n",
      "Predicting 150 steps for rm_id 2323 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2341\n",
      "Predicting 150 steps for rm_id 2341 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2343\n",
      "Predicting 150 steps for rm_id 2343 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2344\n",
      "Predicting 150 steps for rm_id 2344 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2345\n",
      "Predicting 150 steps for rm_id 2345 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2347\n",
      "Predicting 150 steps for rm_id 2347 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2348\n",
      "Predicting 150 steps for rm_id 2348 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2362\n",
      "Predicting 150 steps for rm_id 2362 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2363\n",
      "Predicting 150 steps for rm_id 2363 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2364\n",
      "Predicting 150 steps for rm_id 2364 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2365\n",
      "Predicting 150 steps for rm_id 2365 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2401\n",
      "Predicting 150 steps for rm_id 2401 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2402\n",
      "Predicting 150 steps for rm_id 2402 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2421\n",
      "Predicting 150 steps for rm_id 2421 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2441\n",
      "Predicting 150 steps for rm_id 2441 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2481\n",
      "Predicting 150 steps for rm_id 2481 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2482\n",
      "Predicting 150 steps for rm_id 2482 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2521\n",
      "Predicting 150 steps for rm_id 2521 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2561\n",
      "Predicting 150 steps for rm_id 2561 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2601\n",
      "Predicting 150 steps for rm_id 2601 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2741\n",
      "Predicting 150 steps for rm_id 2741 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2742\n",
      "Predicting 150 steps for rm_id 2742 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2761\n",
      "Predicting 150 steps for rm_id 2761 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2821\n",
      "Predicting 150 steps for rm_id 2821 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2841\n",
      "Predicting 150 steps for rm_id 2841 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2861\n",
      "Predicting 150 steps for rm_id 2861 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 2981\n",
      "Predicting 150 steps for rm_id 2981 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3005\n",
      "Predicting 150 steps for rm_id 3005 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3022\n",
      "Predicting 150 steps for rm_id 3022 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3101\n",
      "Predicting 150 steps for rm_id 3101 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3121\n",
      "Predicting 150 steps for rm_id 3121 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3122\n",
      "Predicting 150 steps for rm_id 3122 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3123\n",
      "Predicting 150 steps for rm_id 3123 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3124\n",
      "Predicting 150 steps for rm_id 3124 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3125\n",
      "Predicting 150 steps for rm_id 3125 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3126\n",
      "Predicting 150 steps for rm_id 3126 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3142\n",
      "Predicting 150 steps for rm_id 3142 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3144\n",
      "Predicting 150 steps for rm_id 3144 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3161\n",
      "Predicting 150 steps for rm_id 3161 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3162\n",
      "Predicting 150 steps for rm_id 3162 because last known date is 2024-12-31 00:00:00\n",
      "Processing rm_id 3201\n",
      "No model for rm_id 3201, setting predicted_weight to 0\n",
      "Processing rm_id 3222\n",
      "No model for rm_id 3222, setting predicted_weight to 0\n",
      "Processing rm_id 3241\n",
      "No model for rm_id 3241, setting predicted_weight to 0\n",
      "Processing rm_id 3265\n",
      "No model for rm_id 3265, setting predicted_weight to 0\n",
      "Processing rm_id 3282\n",
      "No model for rm_id 3282, setting predicted_weight to 0\n",
      "Processing rm_id 3362\n",
      "No model for rm_id 3362, setting predicted_weight to 0\n",
      "Processing rm_id 3381\n",
      "No model for rm_id 3381, setting predicted_weight to 0\n",
      "Processing rm_id 3421\n",
      "No model for rm_id 3421, setting predicted_weight to 0\n",
      "Processing rm_id 3441\n",
      "No model for rm_id 3441, setting predicted_weight to 0\n",
      "Processing rm_id 3461\n",
      "No model for rm_id 3461, setting predicted_weight to 0\n",
      "Processing rm_id 3481\n",
      "No model for rm_id 3481, setting predicted_weight to 0\n",
      "Processing rm_id 3501\n",
      "No model for rm_id 3501, setting predicted_weight to 0\n",
      "Processing rm_id 3541\n",
      "No model for rm_id 3541, setting predicted_weight to 0\n",
      "Processing rm_id 3581\n",
      "No model for rm_id 3581, setting predicted_weight to 0\n",
      "Processing rm_id 3601\n",
      "No model for rm_id 3601, setting predicted_weight to 0\n",
      "Processing rm_id 3621\n",
      "No model for rm_id 3621, setting predicted_weight to 0\n",
      "Processing rm_id 3642\n",
      "No model for rm_id 3642, setting predicted_weight to 0\n",
      "Processing rm_id 3701\n",
      "No model for rm_id 3701, setting predicted_weight to 0\n",
      "Processing rm_id 3761\n",
      "No model for rm_id 3761, setting predicted_weight to 0\n",
      "Processing rm_id 3762\n",
      "No model for rm_id 3762, setting predicted_weight to 0\n",
      "Processing rm_id 3781\n",
      "No model for rm_id 3781, setting predicted_weight to 0\n",
      "Processing rm_id 3802\n",
      "No model for rm_id 3802, setting predicted_weight to 0\n",
      "Processing rm_id 3821\n",
      "No model for rm_id 3821, setting predicted_weight to 0\n",
      "Processing rm_id 3841\n",
      "No model for rm_id 3841, setting predicted_weight to 0\n",
      "Processing rm_id 3865\n",
      "No model for rm_id 3865, setting predicted_weight to 0\n",
      "Processing rm_id 3883\n",
      "No model for rm_id 3883, setting predicted_weight to 0\n",
      "Processing rm_id 3901\n",
      "No model for rm_id 3901, setting predicted_weight to 0\n",
      "Processing rm_id 3921\n",
      "No model for rm_id 3921, setting predicted_weight to 0\n",
      "Processing rm_id 3941\n",
      "No model for rm_id 3941, setting predicted_weight to 0\n",
      "Processing rm_id 4021\n",
      "No model for rm_id 4021, setting predicted_weight to 0\n",
      "Processing rm_id 4044\n",
      "No model for rm_id 4044, setting predicted_weight to 0\n",
      "Processing rm_id 4081\n",
      "No model for rm_id 4081, setting predicted_weight to 0\n",
      "Processing rm_id 4101\n",
      "No model for rm_id 4101, setting predicted_weight to 0\n",
      "Processing rm_id 4161\n",
      "No model for rm_id 4161, setting predicted_weight to 0\n",
      "Processing rm_id 4222\n",
      "No model for rm_id 4222, setting predicted_weight to 0\n",
      "Processing rm_id 4263\n",
      "No model for rm_id 4263, setting predicted_weight to 0\n",
      "Processing rm_id 4302\n",
      "No model for rm_id 4302, setting predicted_weight to 0\n",
      "Processing rm_id 4343\n",
      "No model for rm_id 4343, setting predicted_weight to 0\n",
      "Processing rm_id 4381\n",
      "No model for rm_id 4381, setting predicted_weight to 0\n",
      "Processing rm_id 4401\n",
      "No model for rm_id 4401, setting predicted_weight to 0\n",
      "Processing rm_id 4441\n",
      "No model for rm_id 4441, setting predicted_weight to 0\n",
      "Processing rm_id 4443\n",
      "No model for rm_id 4443, setting predicted_weight to 0\n",
      "Processing rm_id 4461\n",
      "No model for rm_id 4461, setting predicted_weight to 0\n",
      "Processing rm_id 4462\n",
      "No model for rm_id 4462, setting predicted_weight to 0\n",
      "Processing rm_id 4463\n",
      "No model for rm_id 4463, setting predicted_weight to 0\n",
      "Processing rm_id 4481\n",
      "No model for rm_id 4481, setting predicted_weight to 0\n",
      "Processing rm_id 4501\n",
      "No model for rm_id 4501, setting predicted_weight to 0\n"
     ]
    }
   ],
   "source": [
    "prediction_mapping = pd.read_csv('./data/prediction_mapping.csv')\n",
    "prediction_mapping['forecast_start_date'] = pd.to_datetime(prediction_mapping['forecast_start_date'], utc=True).dt.tz_localize(None).dt.normalize()\n",
    "prediction_mapping['forecast_end_date'] = pd.to_datetime(prediction_mapping['forecast_end_date'], utc=True).dt.tz_localize(None).dt.normalize()\n",
    "prediction_mapping = prediction_mapping.sort_values(['rm_id', 'forecast_end_date'])\n",
    "max_date = pd.Timestamp('2025-05-31')\n",
    "lst = []\n",
    "for rm_id, group in prediction_mapping.groupby('rm_id'):\n",
    "    print(f\"Processing rm_id {rm_id}\")\n",
    "    if rm_id not in model_dict:\n",
    "        print(f\"No model for rm_id {rm_id}, setting predicted_weight to 0\")\n",
    "        group['predicted_weight'] = 0\n",
    "    else:\n",
    "    \n",
    "        last_train = series_dict[rm_id].time_index[-1]\n",
    "        n_steps = (max_date - last_train).days - 1\n",
    "        print(f\"Predicting {n_steps} steps for rm_id {rm_id} because last known date is {last_train}\")\n",
    "        preds = model_dict[rm_id].predict(n_steps, series=series_dict[rm_id])\n",
    "        actual_steps = preds.values().clip(min=0)\n",
    "        actual_steps = actual_steps.cumsum()\n",
    "        # group['predicted_weight'] = actual_steps\n",
    "        actual_steps[actual_steps < 100] = 0\n",
    "        group['predicted_weight'] = actual_steps\n",
    "    lst.append(group)\n",
    "\n",
    "df_final = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2bac99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission_path = f'./data/submission/submission_{timestamp}.csv'\n",
    "if not os.path.exists('./data/submission/'):\n",
    "    os.makedirs('./data/submission/')\n",
    "    \n",
    "\n",
    "df_final[['ID', 'predicted_weight']].to_csv(submission_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
